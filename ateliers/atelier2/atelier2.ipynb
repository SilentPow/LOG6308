{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilité d'aimer (score >= 4) toy story sachant que je suis une femme ingénieure de plus de 52 ans (age >= 30: non-jeune). On suppose l'indépendance des facteurs\n",
    "\n",
    "P(score >= 4 | sexe = 'F', age >= 30,  job = 'ing') = P(score >= 4) * P(sexe = 'F' | score >= 4) * P(age >= 30 | score >= 4) * P(job = 'ing' | score >= 4)\n",
    "\n",
    "T: (total nombre de reviews pour toy story)\n",
    "\n",
    "W: (nombre de personnes ingénieurs qui ont donné un score >= 4 à toy story)\n",
    "\n",
    "X: (nombres de scores >= 4 pour toy story dans notre tableau)\n",
    "\n",
    "Y: (nombre de personnes de sexe 'F' qui ont donné un score >= 4 à toy story)\n",
    "\n",
    "Z: (nombre de personnes d'égal ou de plus de 30 ans qui ont donné un score >= 4 à toy story)\n",
    "\n",
    "P(score >= 4): X / T\n",
    "\n",
    "P(sexe = 'F' | score >= 4): Y / X\n",
    "\n",
    "P(age >= 30 | score >= 4): Z / X\n",
    "\n",
    "P(job = 'ing' | score >= 4): W / X\n",
    "\n",
    "Réponse: P(score >= 4 | sexe = 'F', age >= 30) = (X / T) * (Y / X) * (Z / X) * (W / X) = Y * Z * W / (T * X^2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "# Load RData file (requires conversion)\n",
    "votes = pd.read_csv('./data/votes.csv')\n",
    "users = pd.read_csv('./data/u.csv')\n",
    "items = pd.read_csv('./data/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de votes pour toy story: 452\n",
      "nombre de votes pour toy story en haut ou égal à 4: 321\n",
      "probabilité d'avoir un vote de toy story en haut ou égal à 4: 0.7101769911504425\n"
     ]
    }
   ],
   "source": [
    "toy_story_id = items[items['movie.title'].str.contains('Toy Story', case=False, na=False)]['movie.id'].values[0]\n",
    "toy_story_votes = votes[votes['item.id'] == toy_story_id]\n",
    "\n",
    "n_ts_votes = len(toy_story_votes)\n",
    "toy_story_votes_liked = toy_story_votes[toy_story_votes['rating'] >= 4.0]\n",
    "n_ts_votes_liked = len(toy_story_votes_liked)\n",
    "\n",
    "prob_liked = n_ts_votes_liked / n_ts_votes\n",
    "\n",
    "print(f\"nombre de votes pour toy story: {n_ts_votes}\")\n",
    "print(f\"nombre de votes pour toy story en haut ou égal à 4: {n_ts_votes_liked}\")\n",
    "print(f\"probabilité d'avoir un vote de toy story en haut ou égal à 4: {n_ts_votes_liked / n_ts_votes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de bon ratings femele pour toy story: 80\n",
      "nombre de bon ratings ingénieurs pour toy story: 35\n",
      "nombre de bon ratings non-jeune pour toy story en haut ou égal à 4: 164\n",
      "probabilité d'avoir un vote femele de toy story en haut ou égal à 4: 0.24922118380062305\n",
      "probabilité d'avoir un vote ingénieur de toy story en haut ou égal à 4: 0.10903426791277258\n",
      "probabilité d'avoir un vote non-jeune de toy story en haut ou égal à 4: 0.5109034267912772\n"
     ]
    }
   ],
   "source": [
    "merged_user_votes = pd.merge(toy_story_votes_liked, users, left_on='user.id', right_on='id', how='left')\n",
    "female_votes_liked = merged_user_votes[merged_user_votes['gender'] == 'F']\n",
    "eng_votes_liked = merged_user_votes[merged_user_votes['job'] == 'engineer']\n",
    "nonjeune_votes_liked = merged_user_votes[merged_user_votes['age'] >= 30]\n",
    "\n",
    "n_female_ts_votes_liked = len(female_votes_liked)\n",
    "n_eng_ts_votes_liked = len(eng_votes_liked)\n",
    "n_nonjeune_ts_votes_liked = len(nonjeune_votes_liked)\n",
    "\n",
    "prob_female_liked = n_female_ts_votes_liked / n_ts_votes_liked\n",
    "prob_eng_liked = n_eng_ts_votes_liked / n_ts_votes_liked\n",
    "prob_nonjeune_liked = n_nonjeune_ts_votes_liked / n_ts_votes_liked\n",
    "\n",
    "\n",
    "print(f\"nombre de bon ratings femele pour toy story: {n_female_ts_votes_liked}\")\n",
    "print(f\"nombre de bon ratings ingénieurs pour toy story: {n_eng_ts_votes_liked}\")\n",
    "print(f\"nombre de bon ratings non-jeune pour toy story en haut ou égal à 4: {n_nonjeune_ts_votes_liked}\")\n",
    "print(f\"probabilité d'avoir un vote femele de toy story en haut ou égal à 4: {n_female_ts_votes_liked / n_ts_votes_liked}\")\n",
    "print(f\"probabilité d'avoir un vote ingénieur de toy story en haut ou égal à 4: {n_eng_ts_votes_liked / n_ts_votes_liked}\")\n",
    "print(f\"probabilité d'avoir un vote non-jeune de toy story en haut ou égal à 4: {n_nonjeune_ts_votes_liked / n_ts_votes_liked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilité finale: 0.009859465683949332\n"
     ]
    }
   ],
   "source": [
    "prob_total = prob_liked * prob_female_liked * prob_eng_liked * prob_nonjeune_liked\n",
    "print(f\"probabilité finale: {prob_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG for User Mean approach: 0.6851\n",
      "Average NDCG for Item Mean approach: 0.8653\n",
      "Average NDCG for Bayes approach: 0.8870\n",
      "Average NDCG for voisins approach: 0.9163\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def dcg_at_p(relevant_ratings, p):\n",
    "    \"\"\"\n",
    "    Calculate the DCG at position p.\n",
    "    \"\"\"\n",
    "    dcg = 0\n",
    "    for i in range(p):\n",
    "        if i < len(relevant_ratings):\n",
    "            dcg += (relevant_ratings[i]) / np.log2(i + 2)  # 1-based index for log\n",
    "    return dcg\n",
    "\n",
    "def ndcg(actual_ratings, predicted_ratings, p=10):\n",
    "    \"\"\"\n",
    "    Calculate the NDCG at position p.\n",
    "    \"\"\"\n",
    "    # Sort predicted ratings and actual ratings\n",
    "    predicted_ratings_sorted = predicted_ratings.argsort()[::-1]\n",
    "    actual_ratings_sorted = actual_ratings.argsort()[::-1]\n",
    "    \n",
    "    # Get the top p items based on predicted ratings\n",
    "    predicted_top_p = predicted_ratings_sorted[:p]\n",
    "    actual_top_p = actual_ratings_sorted[:p]\n",
    "    \n",
    "    # Map the ratings to relevance levels (0 or 1 for relevance)\n",
    "    predicted_relevance = actual_ratings[predicted_top_p]\n",
    "    actual_relevance = actual_ratings[actual_top_p]\n",
    "    \n",
    "    # Compute DCG and IDCG\n",
    "    dcg = dcg_at_p(predicted_relevance, p)\n",
    "    idcg = dcg_at_p(sorted(actual_relevance, reverse=True), p)\n",
    "    \n",
    "    # Return the NDCG value\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "votes = pd.read_csv('./data/votes.csv')\n",
    "users = pd.read_csv('./data/u.csv')\n",
    "items = pd.read_csv('./data/items.csv')\n",
    "\n",
    "rating_matrix = votes.pivot(index='user.id', columns='item.id', values='rating')\n",
    "#print(rating_matrix.head())\n",
    "\n",
    "# 1. Load data (users as rows, items as columns)\n",
    "ratings_preds_bayes = pd.read_csv(\"./predictions/pred-bayes.csv\", index_col=0)  # Assumes first column is user_id\n",
    "ratings_preds_bayes.index.name = 'movie.id'\n",
    "ratings_preds_bayes.columns = ratings_preds_bayes.columns.str.replace('V', '').astype(int)\n",
    "#print(ratings_preds_bayes.head())\n",
    "\n",
    "ratings_preds_voisins = pd.read_csv(\"./predictions/pred-voisins-obs.csv\")\n",
    "ratings_preds_voisins.index.name = 'movie.id'\n",
    "ratings_preds_voisins.columns = ratings_preds_voisins.columns.str.replace('V', '').astype(int)\n",
    "ratings_preds_voisins.index = range(1, len(ratings_preds_voisins) + 1)\n",
    "#print(ratings_preds_voisins.head())\n",
    "\n",
    "# 2. Compute means\n",
    "user_means = rating_matrix.mean(axis=1, skipna=True)  # Compute mean for each user (ignoring NaNs)\n",
    "item_means = rating_matrix.mean(axis=0, skipna=True)  # Compute mean for each user (ignoring NaNs)\n",
    "\n",
    "#print(user_means)\n",
    "\n",
    "# 3. Predict missing values using user mean\n",
    "predicted_matrix_user = rating_matrix.copy()\n",
    "predicted_matrix_item = rating_matrix.copy()\n",
    "\n",
    "for user in rating_matrix.index:\n",
    "    predicted_matrix_user.loc[user] = user_means[user]  \n",
    "\n",
    "for item in rating_matrix.columns:\n",
    "    predicted_matrix_item[item] = item_means[item]\n",
    "\n",
    "#print(predicted_matrix_user)\n",
    "#print(predicted_matrix_item)\n",
    "\n",
    "# 4. Compute NDCG for each user\n",
    "ndcg_scores_user = []\n",
    "for user in rating_matrix.index:\n",
    "    true_ratings = rating_matrix.loc[user].dropna().values  # Get actual ratings\n",
    "    predicted_ratings = predicted_matrix_user.loc[user, rating_matrix.loc[user].notna()].values  # Use predictions only for rated items\n",
    "\n",
    "    if len(true_ratings) > 1:  # Ensure there's enough data for ranking\n",
    "        ndcg_scores_user.append(ndcg(true_ratings, predicted_ratings))\n",
    "\n",
    "ndcg_scores_item = []\n",
    "for user in rating_matrix.index:\n",
    "    true_ratings = rating_matrix.loc[user].dropna().values  # Get actual ratings\n",
    "    predicted_ratings = predicted_matrix_item.loc[user, rating_matrix.loc[user].notna()].values  # Use predictions only for rated items\n",
    "\n",
    "    if len(true_ratings) > 1:  # Ensure there's enough data for ranking\n",
    "        ndcg_scores_item.append(ndcg(true_ratings, predicted_ratings))\n",
    "\n",
    "#print(ratings_preds_bayes.loc[1])\n",
    "#print(ratings_preds_bayes.index)\n",
    "#print(ratings_preds_bayes.head())\n",
    "ndcg_scores_bayes = []\n",
    "for user in rating_matrix.index:\n",
    "    true_ratings = rating_matrix.loc[user].dropna().values  # Get actual ratings\n",
    "    predicted_ratings = ratings_preds_bayes.loc[user, rating_matrix.loc[user].notna()].values  # Use predictions only for rated items\n",
    "\n",
    "    if len(true_ratings) > 1:  # Ensure there's enough data for ranking\n",
    "        ndcg_scores_bayes.append(ndcg(true_ratings, predicted_ratings))\n",
    "\n",
    "ndcg_scores_voisins = []\n",
    "for user in rating_matrix.index:\n",
    "    true_ratings = rating_matrix.loc[user].dropna().values  # Get actual ratings\n",
    "    predicted_ratings = ratings_preds_voisins.loc[user, rating_matrix.loc[user].notna()].values  # Use predictions only for rated items\n",
    "\n",
    "    if len(true_ratings) > 1:  # Ensure there's enough data for ranking\n",
    "        ndcg_scores_voisins.append(ndcg(true_ratings, predicted_ratings))\n",
    "\n",
    "# 5. Compute average NDCG\n",
    "average_ndcg_user = np.mean(ndcg_scores_user)\n",
    "average_ndcg_item = np.mean(ndcg_scores_item)\n",
    "average_ndcg_bayes = np.mean(ndcg_scores_bayes)\n",
    "average_ndcg_voisins = np.mean(ndcg_scores_voisins)\n",
    "\n",
    "print(f\"Average NDCG for User Mean approach: {average_ndcg_user:.4f}\")\n",
    "print(f\"Average NDCG for Item Mean approach: {average_ndcg_item:.4f}\")\n",
    "print(f\"Average NDCG for Bayes approach: {average_ndcg_bayes:.4f}\")\n",
    "print(f\"Average NDCG for voisins approach: {average_ndcg_voisins:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions à réponse\n",
    "\n",
    "### 1. Quelle serait selon vous la valeur NDCG d'un vote aléatoire? Du vote populaire (les films les plus populaires)?\n",
    "\n",
    "Un vote aléatoire donnerait un NDCG très faible, proche de zéro, car il ne suit aucune logique ou préférence d'utilisateur. Les recommandations seraient complètement indépendantes des intérêts ou des préférences des utilisateurs, ce qui entraînerait une absence de pertinence dans les films recommandés. En revanche, un vote populaire, où les films les plus populaires sont recommandés en fonction des notes moyennes de tous les utilisateurs, pourrait générer un NDCG plus élevé, car ces films sont souvent appréciés par une majorité d’utilisateurs. Cependant, le NDCG ne sera pas nécessairement optimal, car les films populaires ne correspondent pas toujours aux préférences spécifiques de chaque utilisateur.\n",
    "\n",
    "\n",
    "\n",
    "### 2. L'approche bayésienne devrait-elle donner un plus faible NDCG que l'approche u-u ? Devrait-on alors toujours prioriser u-u et laisser tomber l'approche bayésienne?\n",
    "\n",
    "L'approche utilisateur-utilisateur (u-u) peut en effet donner un NDCG plus élevé que l’approche bayésienne dans des situations où les utilisateurs ont des comportements similaires et que les données sont suffisantes pour calculer ces similarités. Cela permet de recommander des films qui sont plus en phase avec les préférences des utilisateurs. Cependant, l'approche bayésienne reste pertinente, notamment dans des contextes où les données sont rares ou incertaines. Elle peut apporter une robustesse supplémentaire en estimant les préférences des utilisateurs même avec peu de données, ce qui permet de mieux gérer les situations d’incertitude. Il n'est donc pas toujours nécessaire de privilégier l'approche u-u au détriment de la bayésienne, car chaque approche a ses avantages selon le contexte.\n",
    "\n",
    "\n",
    "\n",
    "### 3. La mesure du NDCG offre-t-elle une solution plus avantageuse que l'erreur quadratique ou absolue à l'évaluation de la valeur d'une liste de recommandations vis-à-vis de la satisfaction utilisateur?\n",
    "\n",
    "Le NDCG est généralement plus avantageux que l'erreur quadratique ou absolue pour évaluer les systèmes de recommandation, car il prend en compte non seulement la précision des prédictions, mais aussi l’ordre des éléments dans la liste de recommandations, ce qui est crucial pour la satisfaction de l’utilisateur. En effet, les utilisateurs sont plus intéressés par les meilleurs films en haut de la liste que par des prédictions précises sur des films moins pertinents. Tandis que les erreurs quadratiques ou absolues mesurent la différence entre les valeurs prédites et réelles, sans se soucier de l’ordre ou de la pertinence des recommandations, le NDCG offre une mesure qui reflète mieux l’efficacité d’un système de recommandation en termes de satisfaction utilisateur, car il valorise les recommandations les plus pertinentes et bien positionnées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
