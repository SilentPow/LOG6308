{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> École Polytechnique de Montréal <br> Département Génie Informatique et Génie Logiciel <br>  LOG6308 - Systèmes de recommandations <br> </center>\n",
    "\n",
    "## <center> TP2 -- Approche collaboratives par factorisation et par agglomération, et approche contenu </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le travail doit être fait en **équipe de deux**. \n",
    "\n",
    "## Identification de l'équipe: \\<Groupe\\>_eq\\<Numero_Equipe\\>\n",
    "\n",
    "### Groupe de laboratoire: ...\n",
    "\n",
    "### Equipe numéro : ...\n",
    "\n",
    "### Membres:\n",
    "\n",
    "Etudiant 1 (Matricule)\n",
    "\n",
    "Etudiant 2 (Matricule)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Nature de la contribution:** Décrivez brièvement ce qui a été fait par chaque membre de l’équipe. Tous les membres sont censés contribuer au développement. Bien que chaque membre puisse effectuer différentes tâches, vous devez vous efforcer d’obtenir une répartition égale du travail. Soyez précis sur la contribution de chacun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enoncé du TP\n",
    "\n",
    "### Introduction\n",
    "Après avoir exploré les bases des systèmes de recommandation dans le TP1, notamment à travers des approches utilisateur-utilisateur et item-item de filtrage collaboratif, ce deuxième TP aborde les approches basées sur la **factorisation matricielle (SVD)** et le **clustering (K-means)**. Ce TP aborde également des concepts clés tels que la réduction de dimensions, la sélection du nombre optimal de classes, et l’utilisation de catégories pour prédire les votes d’un nouvel utilisateur.\n",
    "\n",
    "À travers ces méthodes, vous serez amenés à analyser les avantages et limites des approches proposées, tout en consolidant votre compréhension des techniques utilisées dans les systèmes de recommandation modernes. Comme dans le TP1, des validations croisées seront mises en œuvre pour évaluer la robustesse des algorithmes. N’hésitez pas à poser des questions si des points restent flous. \n",
    "\n",
    "Bon travail !\n",
    "\n",
    "\n",
    "### Contexte général\n",
    "Vous travaillez avec un jeu de données contenant des votes d’utilisateurs sur des films. Certains votes manquent : votre objectif est de prédire les votes manquants pour chaque utilisateur/film.\n",
    "\n",
    "Pour évaluer vos prédictions, vous utiliserez deux métriques :\n",
    "\n",
    "- Erreur quadratique moyenne (RMSE)\n",
    "- Erreur absolue moyenne (MAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeux de données\n",
    "\n",
    "Vous avez 3 fichiers à votre disposition:\n",
    "\n",
    "- 'Data/votes.csv': Matrice de données de 100 000 votes faits par 943 utilisateurs et portant sur 1682 items.\n",
    "    - **user.id**: Indentifiant de l'utilisateur\n",
    "    - **item.id**: Identifiant de l'item/film\n",
    "    - **rating**: vote attribué à l'item par l'utilisateur\n",
    "    - **timestamp**: Date d'enregistrement du vote (à ignorer pour ce TP) \n",
    "- 'Data/items.csv': Matrice de données sur les films\n",
    "    - **movie.id**: Identifiant du film\n",
    "    - **movie.title**: Nom du film\n",
    "    - **release.date**: Date de sortie\n",
    "    - **video.release.date**: Date de sortie de la video\n",
    "    - **IMDb.URL**: Lien vers le film\n",
    "    - les 19 autres champs sont les categories des films qui sont les suivantes:\n",
    "        \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "- 'Data/u.csv': Matrice de données sur les utilisateurs\n",
    "    - **id**: Identififiant de l'utilisateurs\n",
    "    - **age**: Age de l'utilisateur\n",
    "    - **gender**: Sexe de l'utilisateur\n",
    "    - **job**: Emploi de l'utilisateur\n",
    "    - **zip**: ZIP Code\n",
    "\n",
    "Attention aux espaces et à la casse des differents champs. \n",
    "\n",
    "### Librairies permises\n",
    "\n",
    "- numpy\n",
    "- pandas\n",
    "- seaborn\n",
    "- matplotlib\n",
    "- nltk (KMeansClusterer)\n",
    "- scipy (stat)\n",
    "- tqdm\n",
    "\n",
    "### Rédaction et remise du rapport\n",
    "\n",
    "- Ce notebook constitue à la fois votre code et votre rapport. Il contient un squelette pour guider votre travail.\n",
    "\n",
    "- Complétez directement le notebook, vous êtes libres de créer des nouvelles cellules de code ou de texte.\n",
    "\n",
    "- <u>**IMPORTANT**</u> Remettez le ZIP contenant les données et le notebook sur Moodle avec le nom `MATRICULE1_MATRICULE2.ipynb` pour le notebook et `MATRICULE1_MATRICULE2.zip` pour le zip.\n",
    "\n",
    "\n",
    "### CRITÈRES\n",
    "\n",
    "- La démarche est valide et bien expliquée\n",
    "- Les réponses sont correctes et commentées\n",
    "- L'implémentation est performante et repose sur le calcul linéaire lorsqu'approprié\n",
    "- La présentation est soignée et bien rédigée\n",
    "\n",
    "\n",
    "### CODE D’HONNEUR\n",
    "\n",
    "- __Règle 1__:  Le plagiat de code est bien évidemment interdit. Toute utilisation de code doit être référencée adéquatement. Vous __ne pouvez pas__ soumettre un code écrit par quelqu’un d’autre.\n",
    "\n",
    "- __Règle 2__: Vous êtes libres de discuter des idées et des détails de mise en œuvre avec d'autres équipes. Cependant, vous ne pouvez en aucun cas consulter le code d'une autre équipe ou incorporer leur code dans votre TP.\n",
    "\n",
    "- __Règle 3__:  Vous ne pouvez pas partager votre code publiquement (par exemple, dans un dépôt GitHub public) tant que le cours n'est pas fini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x4odbOSCU4Wa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 : Factorisation par Valeurs Singulières (SVD) (12 points)\n",
    "\n",
    "La factorisation matricielle, via la décomposition SVD, est une méthode puissante pour capturer les relations latentes dans les données. Dans le cadre de ce TP, elle sert à :\n",
    "\n",
    "- Réduire la matrice des votes en identifiant les facteurs latents qui expliquent les interactions utilisateur-item.\n",
    "- Identifier les dimensions les plus significatives (les relations principales) et réduire le bruit lié à des données éparses ou des votes erronés.\n",
    "- Améliorer la qualité des prédictions en reconstruisant les valeurs manquantes sur la base des facteurs latents, tout en diminuant la complexité computationnelle.\n",
    "\n",
    "L’objectif est donc de démontrer comment la réduction de dimensions peut simplifier et impacter la précision des systèmes de recommandation, tout en explorant le compromis entre complexité et performance.\n",
    "\n",
    "**Instructions**:\n",
    "Utilisez l'approche de factorisation par valeurs singulières (SVD) et calculez l'erreur quadratique moyenne. Déterminez le nombre de dimensions à retenir par une méthode de votre choix. Effectuez une validation croisée de 5 replis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Définition des Métriques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_mat(y_pred, y_true):\n",
    "    return np.sqrt(np.nanmean((y_pred - y_true)**2))\n",
    "\n",
    "def MAE_mat(y_pred, y_true):\n",
    "    return np.nanmean(np.abs(y_pred - y_true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Préparation des Données**\n",
    "\n",
    "Pensez a changer le separateur de \"|\" vers \",\" ou reciproquement si vous avez un problemes de chargement de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chargement des votes\n",
    "votes = pd.read_csv('Data/votes.csv', sep =',')# Enlever le sep='|' pour vos données\n",
    "\n",
    "## Conversion du Pandas Datafram en Matrice Utilisateur Item\n",
    "MUI = votes.pivot(index=\"user.id\", columns=\"item.id\", values=\"rating\")\n",
    "MUI.head()\n",
    "\n",
    "\n",
    "## Convertir le DF à une matrice numpy\n",
    "MUI_numpy      = MUI.to_numpy()\n",
    "MUI_numpy_flat = MUI_numpy.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les autres données en mémoire\n",
    "# items \n",
    "items = pd.read_csv('Data/items.csv', sep=',')\n",
    "# users\n",
    "user = pd.read_csv('Data/u.csv', sep=',')\n",
    "# jobs matrices\n",
    "jobs = pd.read_csv('Data/jobs-matrix.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mtSiYhK5dGX"
   },
   "outputs": [],
   "source": [
    "## Defining Figure Size:\n",
    "sns.set(rc={\"figure.figsize\":(12, 6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pour la Validation croisée\n",
    "## Création des indices pour les valeurs différentes de np.nan\n",
    "indices    = np.arange(0, MUI_numpy.shape[0]*MUI_numpy.shape[1])\n",
    "indices_na = indices[~np.isnan(MUI_numpy_flat)]\n",
    "\n",
    "## Split Train Test des indices\n",
    "nbre_replis = 5\n",
    "np.random.shuffle(indices_na)\n",
    "idx_split = np.split(indices_na, nbre_replis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completez la fonction ci-dessous afin de calculer le biais.  Ce calcul permettra de faire l'imputation des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkU_CZIX81Cj"
   },
   "outputs": [],
   "source": [
    "## Calcul de la moyenne attendue\n",
    "\n",
    "def Biais_mat(R):\n",
    "\n",
    "    # Vote Moyen Utilisateur\n",
    "    user_mean = ?\n",
    "\n",
    "    # Prédiction des votes grâce à la moyenne des votes par item de la matrice d'entrainement\n",
    "    item_mean = ?\n",
    "\n",
    "    #calculer la moyenne attendue pour utilisateur\n",
    "    moyenne_U_repeat = ?\n",
    "\n",
    "    #calculer le moyenne attendue pour item\n",
    "    moyenne_I_repeat = ?\n",
    "\n",
    "    # Notre Baseline: vote moyen attendu\n",
    "    R_moy = ?\n",
    "\n",
    "    return R_moy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Définition des Fonctions pour l'approche SVD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif est de faire une decomposition matricielle suivant l'approche SVD. Puis une reduction de dimension en selectionnant un sous ensemble de valeur singulieres (les $k$ plus grandes); et finalement faire une prediction de votes. \n",
    "\n",
    "Completez les fonction suivantes pour effectuer ces tâches. \n",
    "\n",
    "Utilisez la décomposition SVD :   $ R = U \\Sigma V^T $  \n",
    "  \n",
    "Où :  \n",
    "- $M$ est la matrice des votes.  \n",
    "- $ U $ et $ V $ sont des matrices représentant les utilisateurs et les items.  \n",
    "- $ \\Sigma $ est une matrice diagonale contenant les valeurs singulières.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD_decomp(R):\n",
    "    u, sigma, v_trans = ?\n",
    "    #transformation du vecter sigma en une matrice diagonale :\n",
    "    sigma = np.diag(sigma) \n",
    "\n",
    "    return u, sigma, v_trans\n",
    "\n",
    "def SVD_matpred(u, sigma, v_trans, k=5):\n",
    "    #faire une matrice de prédiction en refaisant la multiplication matricielle de u,\n",
    "    #sigma et v_trans mais en utilisant uniquement les k dimensions latentes :\n",
    "    # [compléter le code]\n",
    "    prediction = ?\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_cWXWX5CNte"
   },
   "source": [
    "**Prédiction de votes et calculs d'erreurs**  \n",
    "\n",
    "Maintenant l'objectif est de faire les predictions de votes en fonction du nombre de valeurs singulières selectionné et de calculer les erreurs RMSE et MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_k = [2, 5, 10, 15, 20, 30, 40, 50, 100, 200, 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sans validation croisée**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "list_RMSE_svc = []\n",
    "list_MAE_svc  = []\n",
    "\n",
    "R_biais    = ?\n",
    "R_centered = ?\n",
    "R_centered[np.isnan(R_centered)] = 0\n",
    "\n",
    "u, sigma, v_trans = ?\n",
    "for k in list_k:\n",
    "    # Pred\n",
    "    R_pred = ?\n",
    "\n",
    "    list_RMSE_svc.append(RMSE_mat(R_pred + ?, MUI_numpy))\n",
    "    list_MAE_svc.append(MAE_mat(R_pred + ?, MUI_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la courbe RMSE en fonction du nombre de dimensions.\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Déterminer la meilleure valeur de K\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation croisée**\n",
    "\n",
    "Indication: \n",
    "- On itère sur les replis avant d'itérer sur le nombre de valeurs singulières $k$ que l'on retient. C'est un détail qui permet d'être plus performant en temps de calcul.\n",
    "- Un variable contenant les indices a déjà été crée plus haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9FBrkq97km1",
    "outputId": "a6989688-e658-4b13-c057-afa876635cf7"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "list_RMSE = []\n",
    "list_MAE  = []\n",
    "\n",
    "for i in range(nbre_replis):\n",
    "    list_RMSE_i = []\n",
    "    list_MAE_i  = []\n",
    "\n",
    "    idx_train = ?\n",
    "    idx_valid = ?\n",
    "    \n",
    "    ## On enlève les valeurs de test de la matrice d'entrainement, et les valeurs de train dans la matrice de test\n",
    "    \n",
    "\n",
    "    ## On redonne la structure de matrice aux ensembles de test et d'entrainement\n",
    "    R_train = ? # Valeurs de train\n",
    "    MUI_numpy_valid = ? # Valeurs de test\n",
    "\n",
    "    # Centré\n",
    "    R_biais    = ?\n",
    "    R_centered = ?\n",
    "    R_centered[np.isnan(R_centered)] = 0\n",
    "\n",
    "    # Decomposition\n",
    "    u, sigma, v_trans = ?\n",
    "    for k in list_k:\n",
    "        # Pred\n",
    "        R_pred = ?\n",
    "\n",
    "        list_RMSE_i.append(RMSE_mat(R_pred + ?, MUI_numpy_valid))\n",
    "        list_MAE_i.append(MAE_mat(R_pred + ?, MUI_numpy_valid))\n",
    "\n",
    "    list_RMSE.append(np.array(list_RMSE_i))\n",
    "    list_MAE.append(np.array(list_MAE_i))\n",
    "\n",
    "list_RMSE = np.array(list_RMSE)\n",
    "list_MAE  = np.array(list_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkAnB0N9DFgQ"
   },
   "outputs": [],
   "source": [
    "# Mean per value of k\n",
    "list_RMSE_mean = list_RMSE.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "agsqVEW6ysoU",
    "outputId": "9fa98ff7-7b0a-4ab7-a1bc-cd137619fe2c"
   },
   "outputs": [],
   "source": [
    "values_of_k    = [k for i in range(nbre_replis) for k in list_k]\n",
    "values_of_rmse = list_RMSE.flatten()\n",
    "df_q1 = pd.DataFrame.from_dict({\"Number of Dimensions Taken\": values_of_k, \"Root Mean Square Error on Validation\": values_of_rmse})\n",
    "df_q1.sort_values(\"Number of Dimensions Taken\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "_RaOqfNWx_9V",
    "outputId": "28f8b4d5-55d4-4ed4-e286-1c22bd05a69b"
   },
   "outputs": [],
   "source": [
    "# Afficher les courbes de RMSE en fonction du nombre de dimensions choisies\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6m6-k-byfJN",
    "outputId": "03739bab-b513-4745-cddf-fa92ad58ffa2"
   },
   "outputs": [],
   "source": [
    "# Déterminer la meilleure valeur de K et comparé vos resultats avec ceux obtenus dans l'approches sans validation croisée.\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prédiction**\n",
    "\n",
    "Supposons un nouvel utilisateur qui a visionné le film \"Clockwork Orange\" (numéro 179, indice 178 si les indices commencent à 0).  Utilisez l'approche SVD de prédiction pour lui recommander 10 films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui prend en argument un vecteur ou une matrice de votes d'un utilisateur (lignes de la matrice) et retourne les indices des k films les plus similaires\n",
    "def k_most_similar(votes, k=10):\n",
    "    # à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rotfNytkaP1O"
   },
   "source": [
    "## Question 2 (8 points)\n",
    "\n",
    "L’algorithme K-means est une méthode de regroupement/agglomération (*clustering*) qui divise les utilisateurs (ou items) en plusieurs classes homogènes basées sur leurs similarités. Dans le cadre de ce TP, K-means sert à :\n",
    "\n",
    "- Identifier des groupes d’utilisateurs ou d’items similaires selon leurs interactions (par exemple, des utilisateurs ayant des préférences proches ou des films avec des profils similaires de spectateurs).\n",
    "- Simplifier les prédictions en supposant que les membres d’un même groupe auront des comportements similaires (par exemple, des utilisateurs d’un même cluster auront des votes comparables).\n",
    "- Tester comment le choix du nombre de classes ($k$) influence la précision des prédictions (RMSE) et la capacité du modèle à capturer les relations dans les données.\n",
    "\n",
    "Cette approche permet d’explorer comment le regroupement peut simplifier la personnalisation des recommandations et servir d’alternative (ou de complément) à d'autres méthodes comme SVD ou les filtres collaboratifs.\n",
    "\n",
    "**Instructions :**\n",
    "  \n",
    "Utilisez une approche par agglomération (clustering) pour prédire les votes et calculez l'erreur quadratique moyenne. Utilisez 2, 5, 10, 20, et 40 classes. Prenez l'approche K-moyenne (K-means) et utilisez la corrélation comme mesure de distance et une validation croisée de 5 replis pour établir quel est le nombre de classes à retenir parmi les 5 mentionnés. Une bonne explication de l'algorithme k-means est fournie par Alexandre Ihler dans cette [vidéo](https://www.youtube.com/watch?v=mfqmoUN-Cuw&feature=youtu.be)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JkN3h4E7M3f"
   },
   "source": [
    "### Distances\n",
    "Afin d'effectuer la mesure de distance dans l'approches KMEANS, les fonctions suivantes calculent la distance de Pearson et la distance Euclidienne.\n",
    "\n",
    "#### Distance de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iwA_Xq_9S7q"
   },
   "outputs": [],
   "source": [
    "## Distance de Pearson avec des Nans\n",
    "\n",
    "def PearsonDist(x, y):\n",
    "    if(len(x.shape) < len(y.shape)):# For Cluster Assignment\n",
    "        x = np.expand_dims(x, axis=0).repeat(y.shape[0], axis=0)\n",
    "        nan_or = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "        corr   = [pearsonr(x[i, ~nan_or[i]], y[i, ~nan_or[i]])[0] if((~nan_or[i]).sum() >=2) else 1 for i in range(y.shape[0])]\n",
    "    elif(len(x.shape) > len(y.shape)):\n",
    "        y = np.expand_dims(y, axis=0).repeat(x.shape[0], axis=0)\n",
    "        nan_or = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "        corr   = [pearsonr(x[i, ~nan_or[i]], y[i, ~nan_or[i]])[0] if((~nan_or[i]).sum() >=2) else 1 for i in range(y.shape[0])]\n",
    "    else:# For training phase\n",
    "        nan_or = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "        if((~nan_or).sum() <2):\n",
    "            return 1\n",
    "        corr   = pearsonr(x[~nan_or], y[~nan_or])[0]\n",
    "    return 1 - np.abs(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Euclidienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclidDist(x, y):\n",
    "    # x, y = np.array(x), np.array(y)\n",
    "    nan_or = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "    if((~nan_or).sum() <2):\n",
    "        return nan_or.shape[0]\n",
    "    return np.linalg.norm(x[~nan_or] - y[~nan_or])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAgDmPUnMuBy",
    "outputId": "28dc5088-d4a8-4781-93c1-fd1721e98a20"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "list_RMSE_q2 = []\n",
    "list_MAE_q2  = []\n",
    "list_k_q2    = [2, 5, 10, 20, 40]\n",
    "\n",
    "for i in range(nbre_replis):\n",
    "    list_RMSE_i = []\n",
    "    list_MAE_i  = []\n",
    "\n",
    "    idx_train = ?\n",
    "    idx_valid = ?\n",
    "\n",
    "    # On enlève les valeurs de test de la matrice d'entrainement, et vice versa\n",
    "\n",
    "\n",
    "    # On redonne la structure de matrice aux ensembles de test et d'entrainement\n",
    "    MUI_numpy_train = MUI_numpy_flat_train.reshape(MUI_numpy.shape)\n",
    "    MUI_numpy_valid = MUI_numpy_flat_valid.reshape(MUI_numpy.shape)\n",
    "\n",
    "\n",
    "    for num_cluster in list_k_q2:\n",
    "        ## Remplacer les Nans par le vote moyen pour que K-Means converge en utilisant la fonction Biais_mat définie plus haut.\n",
    "        data                 = MUI_numpy_train.copy()\n",
    "        data[np.isnan(data)] = ?\n",
    "\n",
    "        ## Entrainement du K-Means\n",
    "        kclusterer        = ?\n",
    "        assigned_clusters = ?\n",
    "\n",
    "        ## Extraction des centroides\n",
    "        centroids         = np.array([np.nanmean(MUI_numpy_train[assigned_clusters==k], axis=0) for k in range(num_cluster)])\n",
    "\n",
    "        ## Matrice de prédictions\n",
    "        assigned_clusters_valid = ?\n",
    "        R_pred                  = ?\n",
    "\n",
    "        list_RMSE_i.append(RMSE_mat(R_pred, MUI_numpy_valid))\n",
    "        list_MAE_i.append(MAE_mat(R_pred, MUI_numpy_valid))\n",
    "\n",
    "    list_RMSE_q2.append(np.array(list_RMSE_i))\n",
    "    list_MAE_q2.append(np.array(list_MAE_i))\n",
    "\n",
    "list_RMSE_q2 = np.array(list_RMSE_q2)\n",
    "list_MAE_q2  = np.array(list_MAE_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "m4EKbYDTSERG",
    "outputId": "ecb97cc7-3b66-4771-f895-1709782f25dc"
   },
   "outputs": [],
   "source": [
    "values_of_k_q2    = [k for i in range(nbre_replis) for k in list_k_q2]\n",
    "values_of_rmse_q2 = list_RMSE_q2.flatten()\n",
    "df_q2 = pd.DataFrame.from_dict({\"Number of Dimensions Taken\": values_of_k_q2, \"Root Mean Square Error on Validation\": values_of_rmse_q2})\n",
    "df_q2.sort_values(\"Number of Dimensions Taken\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "HyMnaKiGSQp8",
    "outputId": "7394b319-4add-498f-b2ce-ec80e96f41c4"
   },
   "outputs": [],
   "source": [
    "# Afficher la courbe RMSE en fonction du nombre de dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxN_twfL1acj"
   },
   "outputs": [],
   "source": [
    "# Conclure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
